{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6742c529",
   "metadata": {},
   "source": [
    "\n",
    "# Design Optimization: HW4\n",
    "\n",
    "## Seyed Yousef Soltanian \n",
    " ### you can find the file at https://github.com/YousefSoltanian/MAE598_Design_Optimization.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97275405",
   "metadata": {},
   "source": [
    "### Problem 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2028bad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 -4]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "### defining the objective function and the gradient of objective function\n",
    "def objective(x):\n",
    "    # Calculate the objective function f\n",
    "    f = x[0]**2+(x[1]-3)**2;\n",
    "    \n",
    "    return f\n",
    "\n",
    "def objectiveg(x):\n",
    "    # Calculate the gradient of the objective (row vector)\n",
    "    # df = [df/dx1, df/dx2, ..., df/xn]\n",
    "    \n",
    "    df = np.array([2*x[0], 2*x[1]-6])\n",
    "    return df\n",
    "\n",
    "## test: \n",
    "\n",
    "print(objectiveg(np.array([1,1])))\n",
    "kk = objectiveg(np.array([1,1]))\n",
    "print(np.shape(kk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "8720b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "def constraint(x):\n",
    "    return np.array([x[1]**2 - 2*x[0], (x[1] - 1)**2 + 5*x[0] - 15])\n",
    "## test:\n",
    "x=np.array([[1],[1]])\n",
    "print(constraint(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a7ed236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "def constraintg(x):\n",
    "    # Calculate the gradient of the constraints\n",
    "    # dg = [dg1/dx1, dg1/dx2, ... , dg1/dxn;\n",
    "    #       dg2/dx1, dg2/dx2, ... , dg2/dxn;\n",
    "    #       ...\n",
    "    #       dgm/dx1, dgm/dx2, ... , dgm/dxn]\n",
    "    dg = np.array([[-2, 2*x[1][0]],[5, 2*x[1][0]-2]])\n",
    "    return dg\n",
    "\n",
    "## test:\n",
    "x=np.array([[1],[1]])\n",
    "kk=constraintg(x)\n",
    "\n",
    "print(kk@x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "07434216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lineSearch(f, df, g, dg, x, s, mu_old, w_old):\n",
    "    t = 0.1  # scale factor on current gradient: [0.01, 0.3]\n",
    "    b = 0.8  # scale factor on backtracking: [0.1, 0.8]\n",
    "    a = 1  # maximum step length\n",
    "    \n",
    "    D = s  # direction for x\n",
    "    \n",
    "    # Calculate weights in the merit function using equation (7.77)\n",
    "    w = np.maximum(np.abs(mu_old), 0.5 * (w_old + np.abs(mu_old)))\n",
    "    \n",
    "    # terminate if line search takes too long\n",
    "    count = 0\n",
    "    while count < 100:\n",
    "        # Calculate phi(alpha) using merit function in (7.76)\n",
    "        phi_a = f(x + a * D) + np.dot(w, np.abs(np.minimum(0, -g(x + a * D))))\n",
    "        \n",
    "        # Calculate psi(alpha) in the line search using phi(alpha)\n",
    "        phi0 = f(x) + np.dot(w, np.abs(np.minimum(0, -g(x))))  # phi(0)\n",
    "        dphi0 = np.dot(df(x), D) + np.dot(w, (dg(x) * D) * (g(x) > 0))  # phi'(0)\n",
    "        psi_a = phi0 + t * a * dphi0  # psi(alpha)\n",
    "        \n",
    "        # stop if condition satisfied\n",
    "        if phi_a < psi_a:\n",
    "            break\n",
    "        else:\n",
    "            # backtracking\n",
    "            a = a * b\n",
    "            count = count + 1\n",
    "    \n",
    "    return a, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8991a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def mysqp(f, df, g, dg, x0, opt):\n",
    "    # Set initial conditions\n",
    "    x = x0  # Set the current solution to the initial guess\n",
    "\n",
    "    # Initialize a structure to record the search process\n",
    "    solution = {'x': []}\n",
    "    solution['x'].append(x.copy())  # Save the initial solution\n",
    "\n",
    "    # Initialization of the Hessian matrix\n",
    "    W = np.eye(len(x))  # Start with an identity Hessian matrix\n",
    "\n",
    "    # Initialization of the Lagrange multipliers\n",
    "    mu_old = np.zeros(len(g(x)))  # Start with zero Lagrange multiplier estimates\n",
    "\n",
    "    # Initialization of the weights in the merit function\n",
    "    w = np.zeros(len(g(x)))  # Start with zero weights\n",
    "\n",
    "    # Set the termination criterion\n",
    "    gnorm = np.linalg.norm(df(x) + mu_old @ dg(x))  # norm of Lagrangian gradient\n",
    "\n",
    "    while gnorm > opt['eps']:  # if not terminated\n",
    "        # Implement QP problem and solve\n",
    "        if opt['alg'] == 'myqp':\n",
    "            # Solve the QP subproblem to find s and mu (using your own method)\n",
    "            s, mu_new = solveqp(x, W, df, g, dg)\n",
    "        else:\n",
    "            # Solve the QP subproblem to find s and mu (using MATLAB's solver)\n",
    "            qpalg = {'Algorithm': 'active-set', 'Display': 'off'}\n",
    "            result = minimize(\n",
    "                lambda s: (0.5 * s.T @ W @ s) + (df(x)[0]*s[0]+df(x)[1]*s[1]) ,\n",
    "                np.zeros_like(x).flatten(),\n",
    "                constraints={'type': 'ineq', 'fun': lambda s: g(x) + dg(x) @ s},\n",
    "                options={'disp': False},\n",
    "            )\n",
    "            s = result.s\n",
    "            mu_new = result['ineq']\n",
    "        \n",
    "        # opt['linesearch'] switches line search on or off.\n",
    "        # You can first set the variable \"a\" to different constant values and see how it\n",
    "        # affects the convergence.\n",
    "        if opt['linesearch']:\n",
    "            a, w = lineSearch(f, df, g, dg, x, s, mu_old, w)\n",
    "        else:\n",
    "            a = 0.1\n",
    "\n",
    "        # Update the current solution using the step\n",
    "        dx = a * s  # Step for x\n",
    "        x = x + dx  # Update x using the step\n",
    "\n",
    "        # Update Hessian using BFGS. Use equations (7.36), (7.73), and (7.74)\n",
    "        # Compute y_k\n",
    "        y_k = (\n",
    "            df(x) + mu_new @ dg(x) - df(x - dx) - mu_new @ dg(x - dx)\n",
    "        ).reshape((-1, 1))\n",
    "        # Compute theta\n",
    "        if dx @ y_k >= 0.2 * dx @ W @ dx:\n",
    "            theta = 1\n",
    "        else:\n",
    "            theta = (0.8 * dx @ W @ dx) / (dx @ W @ dx - dx @ y_k)\n",
    "        # Compute dg_k\n",
    "        dg_k = theta * y_k + (1 - theta) * W @ dx\n",
    "        # Compute new Hessian\n",
    "        W = (\n",
    "            W\n",
    "            + np.outer(dg_k, dg_k) / (dg_k @ dx)\n",
    "            - np.outer(W @ dx, W @ dx) / (dx @ W @ dx)\n",
    "        )\n",
    "\n",
    "        # Update termination criterion\n",
    "        gnorm = np.linalg.norm(df(x) + mu_new @ dg(x))  # norm of Lagrangian gradient\n",
    "        mu_old = mu_new\n",
    "\n",
    "        # Save current solution to solution['x']\n",
    "        solution['x'].append(x.copy())\n",
    "\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0cf5708d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[339], line 45\u001b[0m\n\u001b[0;32m     40\u001b[0m     errordlg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInfeasible intial point! You need to start from a feasible one!\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Run your implementation of SQP algorithm. See mysqp.m\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43mmysqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[338], line 33\u001b[0m, in \u001b[0;36mmysqp\u001b[1;34m(f, df, g, dg, x0, opt)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Solve the QP subproblem to find s and mu (using MATLAB's solver)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     qpalg \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive-set\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisplay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 33\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mineq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     s \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39ms\n\u001b[0;32m     40\u001b[0m     mu_new \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mineq\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:705\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    702\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    703\u001b[0m                             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslsqp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 705\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0;32m    706\u001b[0m                           constraints, callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    708\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[0;32m    709\u001b[0m                                        bounds, constraints,\n\u001b[0;32m    710\u001b[0m                                        callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_slsqp_py.py:417\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[1;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    415\u001b[0m fx \u001b[38;5;241m=\u001b[39m wrapped_fun(x)\n\u001b[0;32m    416\u001b[0m g \u001b[38;5;241m=\u001b[39m append(wrapped_grad(x), \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m--> 417\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43m_eval_constraint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcons\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m a \u001b[38;5;241m=\u001b[39m _eval_con_normals(x, cons, la, n, m, meq, mieq)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;66;03m# Call SLSQP\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_slsqp_py.py:479\u001b[0m, in \u001b[0;36m_eval_constraint\u001b[1;34m(x, cons)\u001b[0m\n\u001b[0;32m    476\u001b[0m     c_ieq \u001b[38;5;241m=\u001b[39m zeros(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# Now combine c_eq and c_ieq into a single matrix\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_ieq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%% Main Entrance %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#% Instruction: Please read through the code and fill in blanks \n",
    "#% (marked by ***). Note that you need to do so for every involved\n",
    "#% function, i.e., m files. \n",
    "\n",
    "#%% Optional overhead\n",
    "\n",
    "\n",
    "#%% Optimization settings\n",
    "#% Here we specify the objective function by giving the function handle to a\n",
    "#% variable, for example:\n",
    "f = objective; # replace with your objective function\n",
    "# In the same way, we also provide the gradient of the \n",
    "# objective:\n",
    "df = objectiveg; \n",
    "\n",
    "g = constraint;\n",
    "dg = constraintg;\n",
    "\n",
    "# Note that explicit gradient and Hessian information is only optional.\n",
    "# However, providing these information to the search algorithm will save\n",
    "# computational cost from finite difference calculations for them.\n",
    "\n",
    "# Specify algorithm\n",
    "opt = {}\n",
    "opt['alg'] = 'pyqp'  # 'myqp' or 'matlabqp'\n",
    "\n",
    "# Turn on or off line search. You could turn on line search once other\n",
    "# parts of the program are debugged.\n",
    "opt['linesearch'] = True  # False or True\n",
    "\n",
    "# Set the tolerance to be used as a termination criterion:\n",
    "opt['eps'] = 1e-3\n",
    "\n",
    "# Set the initial guess:\n",
    "x0=np.array([[1],[1]])\n",
    "\n",
    "# Feasibility check for the initial point.\n",
    "if max(g(x0)>0):\n",
    "    errordlg('Infeasible intial point! You need to start from a feasible one!');\n",
    "\n",
    "\n",
    "# Run optimization\n",
    "# Run your implementation of SQP algorithm. See mysqp.m\n",
    "solution = mysqp(f, df, g, dg, x0, opt);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90772b03",
   "metadata": {},
   "source": [
    "### Problem 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387bbcf",
   "metadata": {},
   "source": [
    "For this Problem we have to solve the following optimization problem:\n",
    "\n",
    "$$\n",
    "Minimize_x: \\\n",
    "f(x) = \\sum_{t=0}^{t=T} a(t)\n",
    "$$\n",
    "$$\n",
    "Subjected \\ to: h(T) = 0 \\ , \\ v(T) = 0\n",
    "$$\n",
    "\n",
    "so we can form the Hamiltonian based on the state space equations:\n",
    "\n",
    "$$\n",
    "H = \\lambda^Tf - e = \\begin{bmatrix} \\lambda_1 & \\lambda_2 & \\lambda3 \\end{bmatrix}\\begin{bmatrix}v \\\\ -g-\\frac{a}{m} \\\\ -Ka\\end{bmatrix} \\ = \\frac{\\lambda_1v + \\lambda_2(-g+\\frac{a}{m}) - \\lambda_3Ka - a}{a(\\frac{\\lambda_2}{m} - \\lambda_3K - 1) + \\lambda_1v - \\lambda_2g}\n",
    "$$\n",
    "\n",
    "first we try to find all the $\\lambda_is$:\n",
    "\n",
    "$$\n",
    " -\\frac{\\partial{H}}{\\partial{h}} = \\dot{\\lambda_1} \\rightarrow \\dot{\\lambda_1}  = 0 \\rightarrow \\lambda_1 = c_0 \\\\\n",
    " -\\frac{\\partial{H}}{\\partial{v}} = \\dot{\\lambda_2} \\rightarrow \\dot{\\lambda_2}  = -\\lambda_1 \\rightarrow \\lambda_2 = c_0t +c1 \\\\\n",
    " -\\frac{\\partial{H}}{\\partial{m}} = \\dot{\\lambda_3}  \\rightarrow \\dot{\\lambda_3} = \\lambda_2\\frac{a}{m^2} \\rightarrow \\frac{(0.5c_0t^2 +c_t1)a}{m^2}+c2\\\\\n",
    "$$\n",
    "\n",
    "now, based on the Hamiltonian, we have to chose $a$ in a way to maximize H , by looking at H we can see that the desired a(t) is as:\n",
    "\n",
    "$$\n",
    "a = 1 \\ if \\ \\frac{\\lambda_2}{m} - \\lambda_3K - 1 > 0 \\\\\n",
    "a = 0 \\ if \\ \\frac{\\lambda_2}{m} - \\lambda_3K - 1 > 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac55083",
   "metadata": {},
   "source": [
    "now to get the explicit needed policy, we have to put $\\lambda_2$ and $\\lambda_3$ back to the above equation. To find the constants $c_0,c_1,c_2$ we have to use the boundary conditions $h_0,v_0,t_0$ and $h*,v*$. we basically need to use the obtained equation for a and put it back into our states equations, then using those equations chose each $c_i$ in a way that all the boundaries conditions get satisfied, especially the final one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dlearning",
   "language": "python",
   "name": "dlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
